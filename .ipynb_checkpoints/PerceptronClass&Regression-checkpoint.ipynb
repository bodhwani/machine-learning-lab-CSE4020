{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Assign petal length and petal width to X matrix (150 samples)\n",
    "X = iris.data[:, [2, 3]]\n",
    "\n",
    "# Class labels\n",
    "y = iris.target\n",
    "print y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the X and y arrays into 30 percent test data, and 70 (45 samples) percent training data (105 samples)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Optimization - Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initlalize a new StandardScaler object, sc\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Using the fit method, estimate the sample mean and standard deviation for each feature demension. \n",
    "sc.fit(X_train)\n",
    "\n",
    "# Transform both training and test sets using the sample mean and standard deviations\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Misclassified samples: 4 /', 45)\n",
      "Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the Perceptron implementation \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Initialize a new perceptron object, ppn.\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "\n",
    "# Train the model\n",
    "ppn.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "\n",
    "print('Misclassified samples: %d /' % (y_test != y_pred).sum(), y_test.size)\n",
    "                          \n",
    "\n",
    "\n",
    "# Different performance metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the classification accuracy of the perceptron on the test\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.06632669  1.01074674  0.00227118  2.20552391 -0.00337507  2.01652463\n",
      "  0.01063569  1.16596227  1.2170936   1.00502256  1.90175537  1.01739211\n",
      "  1.07428842  1.08427299  1.13540432 -0.00540582  1.01739211  0.99118871\n",
      "  0.00498944  0.01335395  2.01169258  1.01739211 -0.02564051  0.00227118\n",
      "  1.65334783  0.02588798 -0.00297967  0.99321613  0.95493949 -0.00358479\n",
      "  1.95314814  1.01739211 -0.00337507  1.71462365  1.99956597  1.05539436\n",
      " -0.01194929  1.53336207  1.06724392  1.00693062  1.99161557  0.00791742\n",
      "  2.04887171  0.06621336 -0.00337507]\n",
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor()\n",
    "mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,max_iter=150, shuffle=True, random_state=1,activation='relu')\n",
    "mlp.fit(X_train_std, y_train)\n",
    "y_pred2 = mlp.predict(X_test_std)\n",
    "print y_pred2\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate the classification accuracy of the perceptron on the test\n",
    "print('Accuracy: %.2f' % mlp.score(X_test_std, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
